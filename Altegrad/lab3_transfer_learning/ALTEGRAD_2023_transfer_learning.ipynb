{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DlAfI8mCWAf3"
      },
      "source": [
        "<center><h2>ALTeGraD 2023<br>Lab Session 3: Transfer learning for NLP</h2> 24 / 10 / 2023<br> Dr. G. Shang, H. Abdine<br><br>\n",
        "\n",
        "\n",
        "<b>Student name:</b> Simon Queric\n",
        "\n",
        "</center>\n",
        "\n",
        "<br><br>\n",
        "In this lab we will:\n",
        "* Implement and pretrain a language model with transformer architecture.\n",
        "* Use the pretrained model (transfer learning) to perform a sentiment analysis task which consists of classifying some books reviews into positive and negative ones.\n",
        "* Compare the performance of the pretrained model to a model trained from scratch.\n",
        " <br>\n",
        "\n",
        "<b>The deadline for this lab is October 31, 2023 11:59 PM.</b> More details about the submission and the architecture for this lab can be found in the handout PDF."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IqukuIe0Rb_c"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FF6fjkqgN39"
      },
      "source": [
        "### The Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p0cj9WkSFQwl"
      },
      "outputs": [],
      "source": [
        "class TransformerModel(nn.Module):\n",
        "    def __init__(self, ntoken, nhead, nhid, nlayers, dropout=0.5):\n",
        "        super(TransformerModel, self).__init__()\n",
        "        '''\n",
        "        ntokens: the size of vocabulary\n",
        "        nhid: the hidden dimension of the model.\n",
        "        We assume that embedding_dim = nhid\n",
        "        nlayers: the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
        "        nhead: the number of heads in the multiheadattention models\n",
        "        dropout: the dropout value\n",
        "         '''\n",
        "        self.model_type = \"Transformer\"\n",
        "        self.encoder = nn.Embedding(ntoken, nhid) # fill me, nhid = the dim_embed\n",
        "        self.pos_encoder = PositionalEncoding(nhid) #fill me, the PositionalEncoding class is implemented in the next cell\n",
        "        encoder_layers = nn.TransformerEncoderLayer(nhid, nhead, dim_feedforward=nhid) #fill me we assume nhid = d_model = dim_feedforward\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, nlayers) #fill me\n",
        "        self.nhid = nhid\n",
        "        self.init_weights()\n",
        "\n",
        "    def generate_square_subsequent_mask(self, sz):\n",
        "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
        "        mask = (\n",
        "            mask.float()\n",
        "            .masked_fill(mask == 0, float(\"-inf\"))\n",
        "            .masked_fill(mask == 1, float(0.0))\n",
        "        )\n",
        "        return mask\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.1\n",
        "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "    def forward(self, src, src_mask):\n",
        "        src = self.encoder(src) * math.sqrt(self.nhid)\n",
        "        src = self.pos_encoder(src)\n",
        "        output = self.transformer_encoder(src, src_mask)\n",
        "        return output\n",
        "\n",
        "\n",
        "class ClassificationHead(nn.Module):\n",
        "    def __init__(self, nhid, nclasses):\n",
        "        super(ClassificationHead, self).__init__()\n",
        "        self.decoder = nn.Linear(nhid, nclasses)\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.1\n",
        "        self.decoder.bias.data.zero_()\n",
        "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "    def forward(self, src):\n",
        "        output = self.decoder(src)\n",
        "        return output\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, ntoken, nhead, nhid, nlayers, nclasses, dropout=0.5):\n",
        "        super(Model, self).__init__()\n",
        "        self.base = TransformerModel(ntoken, nhead, nhid, nlayers, dropout)\n",
        "        self.classifier = ClassificationHead(nhid, nclasses)\n",
        "\n",
        "    def forward(self, src, src_mask):\n",
        "        # base model\n",
        "        x = self.base(src, src_mask)\n",
        "        # classifier model\n",
        "        output = self.classifier(x)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kt2QQohaFZry"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, nhid, dropout=0.1, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        pe = torch.zeros(max_len, nhid)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(\n",
        "            torch.arange(0, nhid, 2).float() * (-math.log(10000.0) / nhid)\n",
        "        )\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer(\"pe\", pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[: x.size(0), :]\n",
        "        return self.dropout(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfEYHJx2JW6l"
      },
      "source": [
        "Let's verify if our model works, by applying one inference step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rhb2gkUhJMR0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 500
        },
        "outputId": "f3f4c65c-497d-4857-b35a-5ce096faa3bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-29183690e83f>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdropout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;31m# the dropout value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mntokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnhead\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnhid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnlayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mdummy_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m43\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m21\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0msrc_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_square_subsequent_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1158\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1160\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1162\u001b[0m     def register_full_backward_pre_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1156\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m   1157\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m-> 1158\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
          ]
        }
      ],
      "source": [
        "ntokens = 100 # the size of vocabulary\n",
        "nhid = 200  # hidden dimension\n",
        "nlayers = 4 # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
        "nhead = 2  # the number of heads in the multiheadattention models\n",
        "dropout = 0 # the dropout value\n",
        "\n",
        "model = Model(ntokens, nhead, nhid, nlayers, ntokens, dropout).to(device)\n",
        "dummy_input = torch.tensor([[2, 6, 2, 5, 43, 21]]).to(device)\n",
        "src_mask = model.base.generate_square_subsequent_mask(1).to(device)\n",
        "out = model.forward(dummy_input, src_mask)\n",
        "\n",
        "print(out.shape) # is it the right shape?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i74NN897Fcit"
      },
      "source": [
        "## Vocabulary and Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5qjd26ghWuff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bab0b833-133c-4127-e9fb-9d4baa5468b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-10-28 17:55:25--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/dict.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 577587 (564K) [text/plain]\n",
            "Saving to: ‘dict.txt.1’\n",
            "\n",
            "\rdict.txt.1            0%[                    ]       0  --.-KB/s               \rdict.txt.1          100%[===================>] 564.05K  --.-KB/s    in 0.05s   \n",
            "\n",
            "2023-10-28 17:55:26 (11.7 MB/s) - ‘dict.txt.1’ saved [577587/577587]\n",
            "\n",
            "▁d 1\n",
            "es 1\n",
            "▁l 1\n",
            "en 1\n",
            "on 1\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/dict.txt\n",
        "!head -5 dict.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vFdH_-JeFbGA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68b80c17-ab3e-44ab-8a97-1585578f5a2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "▁trop\n"
          ]
        }
      ],
      "source": [
        "path_vocab = \"dict.txt\"\n",
        "token2ind = {\"<sos>\": 0, \"<pad>\": 1, \"<eos>\": 2, \"<oov>\": 3} # the 4 first indices are reserved to special tokens\n",
        "with open(path_vocab, \"r\") as f:\n",
        "    for idx, line in enumerate(f):\n",
        "        word = line.split()[0].strip()\n",
        "        token2ind[word] =  idx+4\n",
        "\n",
        "ind2token = {idx : word for word, idx in token2ind.items()}\n",
        "\n",
        "print(ind2token[1111])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOExGODajN8p"
      },
      "source": [
        "### Data Loader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y0jN-Ar9i5Q1"
      },
      "outputs": [],
      "source": [
        "import numpy\n",
        "import torch\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "\n",
        "class Dataset(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        path_documents,\n",
        "        path_labels=None,\n",
        "        token2ind={},\n",
        "        max_len=512,\n",
        "        task=\"language_modeling\",\n",
        "    ):\n",
        "        self.task = task\n",
        "        self.max_len = max_len\n",
        "        self.token2ind = token2ind\n",
        "        self.documents = []\n",
        "        self.labels = []\n",
        "        with open(path_documents, \"r\") as f1:\n",
        "            for line in f1:\n",
        "                self.documents.append(line.strip())\n",
        "        if task == \"classification\":\n",
        "            with open(path_labels, \"r\") as f1:\n",
        "                for line in f1:\n",
        "                    self.labels.append(int(line.strip()))\n",
        "            assert len(self.labels) == len(self.documents)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.documents)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        sequence = self.documents[index].split()\n",
        "        if len(sequence) > self.max_len - 1:\n",
        "            sequence = sequence[: self.max_len - 1]\n",
        "        source_sequence = [self.token2ind[\"<sos>\"]]\n",
        "        for word in sequence :\n",
        "            if word in self.token2ind.keys() :\n",
        "                source_sequence.append(self.token2ind[word])\n",
        "            else :\n",
        "                source_sequence.append(self.token2ind[\"<oov>\"])\n",
        "\n",
        "        #source_sequence+= [self.token2ind[\"<pad>\"] for _ in range(self.max_len - len(sequence)-1)] # create input sequence\n",
        "\n",
        "\n",
        "\n",
        "        if self.task == \"language_modeling\":\n",
        "            target = source_sequence[1:]\n",
        "            target.append(self.token2ind[\"<eos>\"])\n",
        "        elif self.task == \"classification\":\n",
        "            target = [self.labels[index]]\n",
        "        sample = {\n",
        "            \"source_sequence\": torch.tensor(source_sequence),\n",
        "            \"target\": torch.tensor(target),\n",
        "        }\n",
        "        return sample\n",
        "\n",
        "\n",
        "def MyCollator(batch):\n",
        "    source_sequences = pad_sequence(\n",
        "        #we use padding to match the length of the sequences in the same batch\n",
        "        [sample[\"source_sequence\"] for sample in batch], padding_value=token2ind[\"<pad>\"]\n",
        "    )\n",
        "    target = pad_sequence(\n",
        "        [sample[\"target\"] for sample in batch], padding_value=token2ind[\"<pad>\"]\n",
        "    )\n",
        "    return source_sequences, target.reshape(-1)\n",
        "\n",
        "\n",
        "def get_loader(\n",
        "    path_documents,\n",
        "    path_labels=None,\n",
        "    token2ind={},\n",
        "    max_len=512,\n",
        "    batch_size=32,\n",
        "    task=\"language_modeling\",\n",
        "):\n",
        "    dataset = Dataset(\n",
        "        path_documents,\n",
        "        path_labels=path_labels,\n",
        "        token2ind=token2ind,\n",
        "        max_len=512,\n",
        "        task=task,\n",
        "    )\n",
        "    data_loader = DataLoader(\n",
        "        dataset=dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        collate_fn=MyCollator,\n",
        "        pin_memory=True,\n",
        "        drop_last=True,\n",
        "    )\n",
        "    return data_loader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTns4lHrjUTa"
      },
      "source": [
        "## The Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4_jwosiLjRsS"
      },
      "outputs": [],
      "source": [
        "def train(\n",
        "    path_data_train,\n",
        "    path_labels_train=None,\n",
        "    path_data_valid=None,\n",
        "    save_interval=-1,\n",
        "    log_interval=5,\n",
        "    task=\"language_modeling\",\n",
        "    batch_size=32,\n",
        "):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    ntokens = len(token2ind)\n",
        "    data_loader = get_loader(\n",
        "        path_data_train,\n",
        "        path_labels_train,\n",
        "        token2ind,\n",
        "        task=task,\n",
        "        batch_size=batch_size,\n",
        "    )\n",
        "\n",
        "    losses = []\n",
        "    for idx, data in enumerate(data_loader): #step 1\n",
        "        optimizer.zero_grad()\n",
        "        src_mask = model.base.generate_square_subsequent_mask(data[0].size(0)).to(\n",
        "            device\n",
        "        )\n",
        "        input = data[0].to(device)\n",
        "        output = model(input, src_mask) #step 2\n",
        "\n",
        "        if task == 'classification':\n",
        "            #last vector only\n",
        "            output = output[-1]\n",
        "        output = output.view(-1, output.shape[-1])\n",
        "        target =  data[1]\n",
        "        target = target.to(device)\n",
        "        loss = criterion(output, target) #fill me, Cross entropy check next cells\n",
        "        loss.backward() # step 3\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5) # prevent exploding gradient\n",
        "        optimizer.step() # step 4\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        #print(loss.item())\n",
        "        if idx % log_interval == 0 and idx > 0:\n",
        "            cur_loss = total_loss / log_interval\n",
        "            print(\n",
        "                \"| epoch {:3d} | {:5d}/{:5d} steps | \"\n",
        "                \"loss {:5.5f} | ppl {:8.3f}\".format(\n",
        "                    epoch, idx, len(data_loader), cur_loss, math.exp(cur_loss),\n",
        "                )\n",
        "            )\n",
        "            losses.append(cur_loss)\n",
        "            total_loss = 0\n",
        "\n",
        "\n",
        "    return losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pgf6BDB9jUr6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "4831b959-d345-4eaf-ec03-d5fdc29dd244"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-aa6395001c97>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mnclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;31m# for classification task only\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mntokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnhead\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnhid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnlayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1158\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1160\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1162\u001b[0m     def register_full_backward_pre_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1156\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m   1157\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m-> 1158\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
          ]
        }
      ],
      "source": [
        "ntokens = len(token2ind)\n",
        "nhid = 200  # the dimension of the feedforward network model in nn.TransformerEncoder\n",
        "nlayers = 4  # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
        "nhead = 2  # the number of heads in the multiheadattention models\n",
        "dropout = 0.1  # the dropout value\n",
        "\n",
        "nclasses = 2 # for classification task only\n",
        "\n",
        "model = Model(ntokens, nhead, nhid, nlayers, ntokens, dropout).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u-OLy4KIkDwf"
      },
      "outputs": [],
      "source": [
        "# optimization paramerters\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=token2ind['<pad>'])\n",
        "lr = 0.0003  # learning rate\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bwh3n9xZQy4e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73ee3f11-b5b0-48be-fa90-6d0f1db63ed7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-10-28 17:55:50--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/pretraining_subset.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10146460 (9.7M) [text/plain]\n",
            "Saving to: ‘pretraining_subset.txt’\n",
            "\n",
            "pretraining_subset. 100%[===================>]   9.68M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2023-10-28 17:55:50 (85.1 MB/s) - ‘pretraining_subset.txt’ saved [10146460/10146460]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/pretraining_subset.txt\n",
        "path_data_train = \"pretraining_subset.txt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0m11g4ScjZaR",
        "outputId": "19ce1e42-241b-4456-d005-626a12f1af13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-c7432bfceab2>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     train(\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mpath_data_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0msave_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-3dcb54512c64>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(path_data_train, path_labels_train, path_data_valid, save_interval, log_interval, task, batch_size)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#step 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         src_mask = model.base.generate_square_subsequent_mask(data[0].size(0)).to(\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         )\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
          ]
        }
      ],
      "source": [
        "#pretraining on a tiny subset\n",
        "log_interval = 500\n",
        "epochs = 1\n",
        "for epoch in range(1, epochs + 1): #5\n",
        "    train(\n",
        "        path_data_train,\n",
        "        save_interval=-1,\n",
        "        task=\"language_modeling\", # fill me\n",
        "        batch_size=16,\n",
        "        log_interval=log_interval,\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MeOM1dOvkO4e"
      },
      "source": [
        "## Text Generation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-BcBC6FSkMH3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b17d55e2-5ce0-4052-f68d-837c4dd50844"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-10-28 17:30:56--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/pretrained_model_4layers.pt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 88093955 (84M) [application/octet-stream]\n",
            "Saving to: ‘pretrained_model_4layers.pt’\n",
            "\n",
            "pretrained_model_4l 100%[===================>]  84.01M   272MB/s    in 0.3s    \n",
            "\n",
            "2023-10-28 17:30:56 (272 MB/s) - ‘pretrained_model_4layers.pt’ saved [88093955/88093955]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/pretrained_model_4layers.pt\n",
        "\n",
        "model = Model(ntokens, nhead, nhid, nlayers, ntokens).to(device)\n",
        "\n",
        "#load the checkpoint\n",
        "checkpoint = torch.load('pretrained_model_4layers.pt', map_location=torch.device('cpu'))\n",
        "#load state dict\n",
        "model.load_state_dict(checkpoint['model_state_dict'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentencepiece"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZ0_H-JKO6N7",
        "outputId": "93b00b77-c1e7-4bcf-b4b5-93b2e153bcb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.99\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tBRRVsWqlIoQ",
        "outputId": "9568f04a-f8c1-4e9c-8c1e-945d99152d81",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-10-28 17:31:08--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/sentencepiece.french.model\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115362 (1.1M) [application/octet-stream]\n",
            "Saving to: ‘sentencepiece.french.model’\n",
            "\n",
            "\r          sentencep   0%[                    ]       0  --.-KB/s               \rsentencepiece.frenc 100%[===================>]   1.06M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2023-10-28 17:31:08 (17.9 MB/s) - ‘sentencepiece.french.model’ saved [1115362/1115362]\n",
            "\n",
            "['▁Bonjour', '▁les', '▁amis', '!']\n",
            "Bonjour les amis!\n"
          ]
        }
      ],
      "source": [
        "# !pip install sentencepiece   # uncomment this if you are using google colab\n",
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/sentencepiece.french.model\n",
        "\n",
        "import sentencepiece as spm\n",
        "\n",
        "s = spm.SentencePieceProcessor(model_file='sentencepiece.french.model') #load sentencepiece model\n",
        "\n",
        "#examples\n",
        "encoded = s.encode_as_pieces(\"Bonjour les amis!\")\n",
        "decoded = s.decode_pieces(encoded)\n",
        "print(encoded)\n",
        "print(decoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TtLlV05pkQI3"
      },
      "outputs": [],
      "source": [
        "def infer_next_token(sent):\n",
        "    model.eval()\n",
        "    sent_pieces = s.encode_as_pieces(sent)\n",
        "    source = [token2ind['<sos>']] + [token2ind[el] for el in sent_pieces] # list of tokens\n",
        "    source = torch.tensor(source).to(device)\n",
        "    source = source.reshape(-1, 1)\n",
        "    src_mask = model.base.generate_square_subsequent_mask(source.size(0)).to(device)\n",
        "    out = model(source, src_mask)\n",
        "    next_token_ind = torch.argmax(out[-1])\n",
        "    return next_token_ind, out\n",
        "\n",
        "def infer_next_tokens(sent, max_len=2):\n",
        "    length = 0\n",
        "\n",
        "    next_token = \"\"\n",
        "    while length <= max_len and next_token != \"<eos>\" :\n",
        "        next_token_ind, out = infer_next_token(sent)\n",
        "        next_token = ind2token[int(next_token_ind)]\n",
        "        sent += \" \" + next_token\n",
        "        length+=1\n",
        "\n",
        "    return sent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f83Nn5nSly4v"
      },
      "outputs": [],
      "source": [
        "sent = \"Bonjour les\"\n",
        "next_token, out = infer_next_token(sent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o73Xh1ZRoPL-",
        "outputId": "088689fb-cf2e-4fb7-cb15-627ddd555fd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Bonjourles gens qui ont été très accueillants et sympathiques.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "s.decode_pieces(infer_next_tokens(sent, max_len=10).split()[:-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lp7mjVzomoZ3"
      },
      "source": [
        "### Supervised task"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0K1BZsblmEmx",
        "outputId": "694fa547-439c-48b1-e18b-4ab9ca2db581",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-10-28 17:31:10--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/train.review.spm\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1495960 (1.4M) [text/plain]\n",
            "Saving to: ‘train.review.spm’\n",
            "\n",
            "\rtrain.review.spm      0%[                    ]       0  --.-KB/s               \rtrain.review.spm    100%[===================>]   1.43M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2023-10-28 17:31:11 (22.8 MB/s) - ‘train.review.spm’ saved [1495960/1495960]\n",
            "\n",
            "--2023-10-28 17:31:11--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/train.label\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3200 (3.1K) [text/plain]\n",
            "Saving to: ‘train.label’\n",
            "\n",
            "train.label         100%[===================>]   3.12K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-10-28 17:31:11 (67.7 MB/s) - ‘train.label’ saved [3200/3200]\n",
            "\n",
            "--2023-10-28 17:31:11--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/test.review.spm\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1864544 (1.8M) [text/plain]\n",
            "Saving to: ‘test.review.spm’\n",
            "\n",
            "test.review.spm     100%[===================>]   1.78M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2023-10-28 17:31:11 (26.2 MB/s) - ‘test.review.spm’ saved [1864544/1864544]\n",
            "\n",
            "--2023-10-28 17:31:11--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/test.label\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4000 (3.9K) [text/plain]\n",
            "Saving to: ‘test.label’\n",
            "\n",
            "test.label          100%[===================>]   3.91K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-10-28 17:31:11 (41.7 MB/s) - ‘test.label’ saved [4000/4000]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/train.review.spm\n",
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/train.label\n",
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/test.review.spm\n",
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/test.label\n",
        "\n",
        "path_data_train = \"train.review.spm\"\n",
        "path_labels_train = \"train.label\"\n",
        "\n",
        "path_data_valid = \"test.review.spm\"\n",
        "path_labels_valid = \"test.label\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_MLfvjiom2SL"
      },
      "outputs": [],
      "source": [
        "# a function to evaluate the validation accuracy of the model.\n",
        "def evaluate_accuracy(data_loader):\n",
        "    n=0\n",
        "    accuracy = 0\n",
        "    for idx, data in enumerate(data_loader) :\n",
        "        src_mask = model.base.generate_square_subsequent_mask(data[0].size(0)).to(\n",
        "            device\n",
        "        )\n",
        "        input = data[0].to(device)\n",
        "        output = model(input, src_mask) #step 2\n",
        "        output = output[-1]\n",
        "        pred = torch.argmax(output, axis=1)\n",
        "        target = data[1].to(device)\n",
        "        accuracy+= torch.sum(target==pred)/len(target)\n",
        "        n+=1\n",
        "    accuracy /= n\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qzmx7T7xoa6v"
      },
      "outputs": [],
      "source": [
        "#save the base model to be loaded later in the fine-tuning phase\n",
        "torch.save({\"model_state_dict\": model.base.state_dict(),}, \"pretrained_model_4layers_no_class_head.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i-xclMCpnVpw",
        "outputId": "913ed6cf-5ac7-4985-cff5-b25e1c6a2905",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=====Trainig FROM SCRATCH======\n",
            "| epoch   1 |    50/  200 steps | loss 0.73740 | ppl    2.090\n",
            "| epoch   1 |   100/  200 steps | loss 0.78746 | ppl    2.198\n",
            "| epoch   1 |   150/  200 steps | loss 0.76382 | ppl    2.146\n",
            "| epoch   2 |    50/  200 steps | loss 0.65880 | ppl    1.932\n",
            "| epoch   2 |   100/  200 steps | loss 0.55779 | ppl    1.747\n",
            "| epoch   2 |   150/  200 steps | loss 0.61520 | ppl    1.850\n",
            "| epoch   3 |    50/  200 steps | loss 0.44240 | ppl    1.556\n",
            "| epoch   3 |   100/  200 steps | loss 0.38282 | ppl    1.466\n",
            "| epoch   3 |   150/  200 steps | loss 0.37633 | ppl    1.457\n",
            "| epoch   4 |    50/  200 steps | loss 0.33702 | ppl    1.401\n",
            "| epoch   4 |   100/  200 steps | loss 0.17053 | ppl    1.186\n",
            "| epoch   4 |   150/  200 steps | loss 0.22943 | ppl    1.258\n",
            "| epoch   5 |    50/  200 steps | loss 0.09951 | ppl    1.105\n",
            "| epoch   5 |   100/  200 steps | loss 0.10208 | ppl    1.107\n",
            "| epoch   5 |   150/  200 steps | loss 0.04828 | ppl    1.049\n",
            "| epoch   6 |    50/  200 steps | loss 0.03497 | ppl    1.036\n",
            "| epoch   6 |   100/  200 steps | loss 0.02148 | ppl    1.022\n",
            "| epoch   6 |   150/  200 steps | loss 0.13385 | ppl    1.143\n",
            "| epoch   7 |    50/  200 steps | loss 0.01831 | ppl    1.018\n",
            "| epoch   7 |   100/  200 steps | loss 0.04748 | ppl    1.049\n",
            "| epoch   7 |   150/  200 steps | loss 0.05590 | ppl    1.057\n",
            "| epoch   8 |    50/  200 steps | loss 0.00030 | ppl    1.000\n",
            "| epoch   8 |   100/  200 steps | loss 0.01269 | ppl    1.013\n",
            "| epoch   8 |   150/  200 steps | loss 0.03682 | ppl    1.038\n",
            "| epoch   9 |    50/  200 steps | loss 0.04032 | ppl    1.041\n",
            "| epoch   9 |   100/  200 steps | loss 0.04604 | ppl    1.047\n",
            "| epoch   9 |   150/  200 steps | loss 0.00284 | ppl    1.003\n",
            "| epoch  10 |    50/  200 steps | loss 0.03174 | ppl    1.032\n",
            "| epoch  10 |   100/  200 steps | loss 0.01470 | ppl    1.015\n",
            "| epoch  10 |   150/  200 steps | loss 0.01284 | ppl    1.013\n",
            "| epoch  11 |    50/  200 steps | loss 0.00070 | ppl    1.001\n",
            "| epoch  11 |   100/  200 steps | loss 0.02384 | ppl    1.024\n",
            "| epoch  11 |   150/  200 steps | loss 0.00003 | ppl    1.000\n",
            "| epoch  12 |    50/  200 steps | loss 0.07234 | ppl    1.075\n",
            "| epoch  12 |   100/  200 steps | loss 0.02635 | ppl    1.027\n",
            "| epoch  12 |   150/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  13 |    50/  200 steps | loss 0.03069 | ppl    1.031\n",
            "| epoch  13 |   100/  200 steps | loss 0.00042 | ppl    1.000\n",
            "| epoch  13 |   150/  200 steps | loss 0.01360 | ppl    1.014\n",
            "| epoch  14 |    50/  200 steps | loss 0.04294 | ppl    1.044\n",
            "| epoch  14 |   100/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  14 |   150/  200 steps | loss 0.04115 | ppl    1.042\n",
            "| epoch  15 |    50/  200 steps | loss 0.05203 | ppl    1.053\n",
            "| epoch  15 |   100/  200 steps | loss 0.04547 | ppl    1.047\n",
            "| epoch  15 |   150/  200 steps | loss 0.00002 | ppl    1.000\n",
            "\n",
            "=====PRETRAINED MODEL======\n",
            "| epoch   1 |    50/  200 steps | loss 0.80264 | ppl    2.231\n",
            "| epoch   1 |   100/  200 steps | loss 0.67145 | ppl    1.957\n",
            "| epoch   1 |   150/  200 steps | loss 0.63263 | ppl    1.883\n",
            "| epoch   2 |    50/  200 steps | loss 0.49874 | ppl    1.647\n",
            "| epoch   2 |   100/  200 steps | loss 0.48886 | ppl    1.630\n",
            "| epoch   2 |   150/  200 steps | loss 0.51610 | ppl    1.675\n",
            "| epoch   3 |    50/  200 steps | loss 0.40891 | ppl    1.505\n",
            "| epoch   3 |   100/  200 steps | loss 0.41942 | ppl    1.521\n",
            "| epoch   3 |   150/  200 steps | loss 0.47696 | ppl    1.611\n",
            "| epoch   4 |    50/  200 steps | loss 0.33264 | ppl    1.395\n",
            "| epoch   4 |   100/  200 steps | loss 0.32382 | ppl    1.382\n",
            "| epoch   4 |   150/  200 steps | loss 0.32313 | ppl    1.381\n",
            "| epoch   5 |    50/  200 steps | loss 0.33381 | ppl    1.396\n",
            "| epoch   5 |   100/  200 steps | loss 0.27800 | ppl    1.320\n",
            "| epoch   5 |   150/  200 steps | loss 0.31149 | ppl    1.365\n",
            "| epoch   6 |    50/  200 steps | loss 0.19812 | ppl    1.219\n",
            "| epoch   6 |   100/  200 steps | loss 0.29851 | ppl    1.348\n",
            "| epoch   6 |   150/  200 steps | loss 0.30140 | ppl    1.352\n",
            "| epoch   7 |    50/  200 steps | loss 0.20157 | ppl    1.223\n",
            "| epoch   7 |   100/  200 steps | loss 0.19476 | ppl    1.215\n",
            "| epoch   7 |   150/  200 steps | loss 0.19164 | ppl    1.211\n",
            "| epoch   8 |    50/  200 steps | loss 0.06811 | ppl    1.070\n",
            "| epoch   8 |   100/  200 steps | loss 0.17418 | ppl    1.190\n",
            "| epoch   8 |   150/  200 steps | loss 0.19823 | ppl    1.219\n",
            "| epoch   9 |    50/  200 steps | loss 0.13182 | ppl    1.141\n",
            "| epoch   9 |   100/  200 steps | loss 0.13232 | ppl    1.141\n",
            "| epoch   9 |   150/  200 steps | loss 0.10715 | ppl    1.113\n",
            "| epoch  10 |    50/  200 steps | loss 0.04912 | ppl    1.050\n",
            "| epoch  10 |   100/  200 steps | loss 0.06297 | ppl    1.065\n",
            "| epoch  10 |   150/  200 steps | loss 0.10009 | ppl    1.105\n",
            "| epoch  11 |    50/  200 steps | loss 0.08849 | ppl    1.093\n",
            "| epoch  11 |   100/  200 steps | loss 0.12127 | ppl    1.129\n",
            "| epoch  11 |   150/  200 steps | loss 0.03993 | ppl    1.041\n",
            "| epoch  12 |    50/  200 steps | loss 0.03898 | ppl    1.040\n",
            "| epoch  12 |   100/  200 steps | loss 0.07643 | ppl    1.079\n",
            "| epoch  12 |   150/  200 steps | loss 0.00740 | ppl    1.007\n",
            "| epoch  13 |    50/  200 steps | loss 0.04357 | ppl    1.045\n",
            "| epoch  13 |   100/  200 steps | loss 0.03806 | ppl    1.039\n",
            "| epoch  13 |   150/  200 steps | loss 0.00184 | ppl    1.002\n",
            "| epoch  14 |    50/  200 steps | loss 0.06112 | ppl    1.063\n",
            "| epoch  14 |   100/  200 steps | loss 0.00653 | ppl    1.007\n",
            "| epoch  14 |   150/  200 steps | loss 0.01102 | ppl    1.011\n",
            "| epoch  15 |    50/  200 steps | loss 0.03365 | ppl    1.034\n",
            "| epoch  15 |   100/  200 steps | loss 0.02885 | ppl    1.029\n",
            "| epoch  15 |   150/  200 steps | loss 0.00122 | ppl    1.001\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from_scratch_settings = [True, False]\n",
        "\n",
        "from_scratch_valid_acc = []\n",
        "pretrained_valid_acc = []\n",
        "lr = 0.0001\n",
        "\n",
        "for from_scratch in from_scratch_settings:\n",
        "    model = Model(ntokens, nhead, nhid, nlayers, 2, dropout).to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    if not from_scratch:\n",
        "        print(\"=====PRETRAINED MODEL======\")\n",
        "        #load checkpoint\n",
        "        checkpoint = torch.load(\"pretrained_model_4layers_no_class_head.pt\")\n",
        "        #load state dict\n",
        "        model.base.load_state_dict(checkpoint['model_state_dict'])\n",
        "    else:\n",
        "        print(\"=====Trainig FROM SCRATCH======\")\n",
        "    epochs = 15\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        train(\n",
        "            path_data_train,\n",
        "            path_labels_train,\n",
        "            save_interval=-1,\n",
        "            task='classification',\n",
        "            batch_size=8,\n",
        "            log_interval=50,\n",
        "        )\n",
        "        acc = evaluate_accuracy(\n",
        "            get_loader(\n",
        "                path_data_valid,\n",
        "                path_labels_valid,\n",
        "                token2ind=token2ind,\n",
        "                batch_size=20,\n",
        "                task='classification',\n",
        "            )\n",
        "        )\n",
        "        if from_scratch:\n",
        "            from_scratch_valid_acc.append(acc)\n",
        "        else:\n",
        "            pretrained_valid_acc.append(acc)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RCpBIdTHojm6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 619
        },
        "outputId": "62cd0b14-b014-4c2f-eedb-b580128d7afd"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 900x700 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "#Visualize the accuracy\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig = plt.figure(figsize=(9, 7))\n",
        "acc1 = [float(pretrained_valid_acc[i]) for i in range(len(pretrained_valid_acc))]\n",
        "acc2 = [float(from_scratch_valid_acc[i]) for i in range(len(from_scratch_valid_acc))]\n",
        "plt.plot(acc1)\n",
        "plt.plot(acc2)\n",
        "plt.legend([\"Evolution of accuracy with a pretrained model\", \"Evolution of accuracy with training from scratch\"])\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "1f3cfdeab8dd8f9900bd16266619de191cf0f5e09365d74b1fba1714dce58066"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}